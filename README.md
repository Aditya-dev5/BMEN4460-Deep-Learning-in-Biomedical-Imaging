# Deep Architectures for Medical Image Segmentation  
*A Comparative Study on BraTS 2020 Brain Tumor MRI Dataset*  

## ğŸ§  Overview  
This project compares four U-Netâ€“based architectures â€” **Vanilla U-Net**, **U-Net++**, **Attention U-Net**, and **Swin U-Net** â€” for automated brain tumor segmentation on the **BraTS 2020** dataset. It evaluates how dense skip connections, attention gates, and transformer-based encoders impact segmentation accuracy.

## Files (Training and evaluation of each of the 4 models and final project report)
1. UNet++.ipynb
2. Vanilla-UNet.ipynb
3. attention-UNet.ipynb
4. swin-UNet.ipynb
5. Report.pdf

## âš™ï¸ Highlights  
- Implemented 4 U-Net variants in **PyTorch**  
- Multimodal MRI inputs: *T1, T1c, T2, FLAIR*  
- Metrics: **Dice**, **Jaccard**, qualitative overlays  
- Best performance: *Attention U-Net* â€” **Dice = 0.893**, **Jaccard = 0.812**

## ğŸš€ Usage  
```bash
git clone https://github.com/Aditya-dev5/BMEN4460-Deep-Learning-in-Biomedical-Imaging.git
cd BMEN4460-Deep-Learning-in-Biomedical-Imaging
